{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 6\n",
    "\n",
    "Neste desafio, vamos praticar _feature engineering_, um dos processos mais importantes e trabalhosos de ML. Utilizaremos o _data set_ [Countries of the world](https://www.kaggle.com/fernandol/countries-of-the-world), que contém dados sobre os 227 países do mundo com informações sobre tamanho da população, área, imigração e setores de produção.\n",
    "\n",
    "> Obs.: Por favor, não modifique o nome das funções de resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Setup_ geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import scipy.stats as sct\n",
    "from sklearn.datasets import load_digits, fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, Binarizer, KBinsDiscretizer,\n",
    "    MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas configurações para o matplotlib.\n",
    "#%matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "figsize(12, 8)\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [\n",
    "    \"Country\", \"Region\", \"Population\", \"Area\", \"Pop_density\", \"Coastline_ratio\",\n",
    "    \"Net_migration\", \"Infant_mortality\", \"GDP\", \"Literacy\", \"Phones_per_1000\",\n",
    "    \"Arable\", \"Crops\", \"Other\", \"Climate\", \"Birthrate\", \"Deathrate\", \"Agriculture\",\n",
    "    \"Industry\", \"Service\"\n",
    "]\n",
    "\n",
    "countries.columns = new_column_names\n",
    "\n",
    "#countries.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "\n",
    "Esse _data set_ ainda precisa de alguns ajustes iniciais. Primeiro, note que as variáveis numéricas estão usando vírgula como separador decimal e estão codificadas como strings. Corrija isso antes de continuar: transforme essas variáveis em numéricas adequadamente.\n",
    "\n",
    "Além disso, as variáveis `Country` e `Region` possuem espaços a mais no começo e no final da string. Você pode utilizar o método `str.strip()` para remover esses espaços."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicia sua análise a partir daqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ajustando as variaveis numericas:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao para transformar os valores\n",
    "def transforma_valores_df (df, nome_colunas):\n",
    "    pd.set_option('mode.chained_assignment','warn')\n",
    "    #salva tamanho da lista com o nome das colunas\n",
    "    x = len(nome_colunas)\n",
    "    #de i ate o tamanho da lista == 15\n",
    "    for i in range(x):\n",
    "        # salvando a qtd de elemntos da coluna em questao\n",
    "        y = len(df[nome_colunas[i]])\n",
    "        variavel = nome_colunas[i]\n",
    "        #print(variavel)\n",
    "        #pra cada elemento da lista transforma os valores\n",
    "        #percorre valor por valor alterando a virgula por ponto \n",
    "        for j in range(y):\n",
    "            valor = str(df.loc[j,variavel])\n",
    "            if (valor != 'NaN') and (valor != 'nan') and (valor != 'Nan'):\n",
    "                valor = float(valor.replace(\",\",\".\"))\n",
    "                #print(valor)\n",
    "                df.loc[j,variavel] = valor\n",
    "        #altera o tipo da coluna\n",
    "        df[variavel] = df[variavel].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando em df auxiliar\n",
    "aux = pd.DataFrame(countries)\n",
    "lista_colunas_object = list(aux.select_dtypes(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Region'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tirando os 2 primeiros elementos da lista ==  Region e Country\n",
    "lista_colunas_object.pop(0)\n",
    "lista_colunas_object.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamando a funcao para tranformar os valores\n",
    "transforma_valores_df(aux,lista_colunas_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ajustando as variáveis Country e Region__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux['Country'] = [x.strip() for x in aux['Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux['Region'] = [x.strip() for x in aux['Region']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questao 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux['Climate'].value_counts().nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aux.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#questao 2\n",
    "#quantos países se encontram acima do 90º percentil?\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"quantile\")\n",
    "\n",
    "discretizer.fit(aux[[\"Pop_density\"]])\n",
    "\n",
    "pop_bins = discretizer.transform(aux[[\"Pop_density\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretizer.bin_edges_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval(bin_idx, bin_edges):\n",
    "  return f\"{np.round(bin_edges[bin_idx], 2):.2f} ⊢ {np.round(bin_edges[bin_idx+1], 2):.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin_edges_quantile = discretizer.bin_edges_[0]\n",
    "\n",
    "print(f\"Bins quantile\")\n",
    "print(f\"interval: #elements\\n\")\n",
    "for i in range(len(discretizer.bin_edges_[0])-1):\n",
    "    print(f\"{get_interval(i, bin_edges_quantile)}: {sum(pop_bins[:, 0] == i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.70 ⊢ 396.74\n"
     ]
    }
   ],
   "source": [
    "#print(get_interval(8, bin_edges_quantile))#8  pq vai de 0 a 9, entao 8 que é o nono intervalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges_quantile = discretizer.bin_edges_[0]\n",
    "pop_intervals = pd.Series(pop_bins.flatten().astype(np.int)).apply(get_interval, args=(bin_edges_quantile,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.concat([aux, pd.DataFrame(pop_intervals, columns=[\"Pop_density_interval\"])], axis=1)\n",
    "\n",
    "#data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = data_encoded[['Country', 'Pop_density_interval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_paises = ax2[ax2['Pop_density_interval'] == '253.70 ⊢ 396.74']['Country'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questao 3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Nessa questao eu errei da primeira vez pq eu tirei o nan da conta___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False, dtype=np.int, handle_unknown='ignore')\n",
    "\n",
    "region_encoded = one_hot_encoder.fit_transform(aux[[\"Region\"]])\n",
    "#climate_encoded = one_hot_encoder.fit_transform(aux[[\"Climate\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one_hot_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(aux[[\"Climate\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirando os valores nan de X\n",
    "res = [] \n",
    "for i in X: \n",
    "    valor = str(i[0])\n",
    "    if valor != 'nan': \n",
    "        #print(i[0])\n",
    "        res.append(i[0]) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo res para array dnv no msm formato de antes\n",
    "X = np.array(res)\n",
    "X = np.reshape(X, (-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False, dtype=np.int, handle_unknown='ignore')\n",
    "climate_encoded = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "climate_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "climate_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "tota_novos_atributos = region_encoded.shape[1]+climate_encoded.shape[1]+1 \n",
    "#+1 por causa do nan\n",
    "#depois ver uma alternativa de fazer o procedimento com nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tota_novos_atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questao 4__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Essa questao nao entendi nem a pau ainda por que diabos tem que pegar e fazer um pipeline com padrozinacao___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_pipe = aux.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pipeline__\n",
    "- Preencha as variáveis do tipo int64 e float64 com suas respectivas medianas.\n",
    "- Padronize essas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montando o pipeline\n",
    "aux_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"zscore\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capturando as colunas especificadas\n",
    "colunas_int_float = list(aux_pipe.select_dtypes(include=['int64','float64']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando o pipeline\n",
    "pipeline_transformation = aux_pipeline.fit_transform(aux_pipe[colunas_int_float])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df depois do pipeline\n",
    "axu_pos_pipeline = pd.DataFrame(pipeline_transformation, columns=colunas_int_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questao 5__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Descubra o número de outliers da variável Net_migration segundo o método do _boxplot ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nessa questao a primeira vez, eu errei porque entendi errado__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_migration_outlier = aux.Net_migration.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net_migration_outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.boxplot(net_migration_outlier, orient=\"horizontal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = net_migration_outlier.quantile(0.25)\n",
    "q3 = net_migration_outlier.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "non_outlier_interval_iqr = [q1 - 1.5 * iqr, q3 + 1.5 * iqr]\n",
    "\n",
    "#print(f\"Faixa considerada \\\"normal\\\": {non_outlier_interval_iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encontrando os pontos fora da faixa\n",
    "outliers_iqr = net_migration_outlier[(net_migration_outlier < non_outlier_interval_iqr[0]) | (net_migration_outlier > non_outlier_interval_iqr[1])]\n",
    "outliers_iqr_abaixo = net_migration_outlier[(net_migration_outlier < non_outlier_interval_iqr[0])]\n",
    "outliers_iqr_acima = net_migration_outlier[(net_migration_outlier > non_outlier_interval_iqr[1])]\n",
    "outliers_abaixo = outliers_iqr_abaixo.count()\n",
    "outliers_acima = outliers_iqr_acima.count()\n",
    "removeria = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Qtd de valores fora da faixa considerada normal', outliers_iqr.count())\n",
    "print('Qtd total de valores da variavel', net_migration_outlier.count())\n",
    "print('Qtd total de valores abaixo da faixa considerada normal', outliers_iqr_abaixo.count())\n",
    "print('Qtd total de valores acima da faixa considerada normal', outliers_iqr_acima.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deveria remover da análise as observações consideradas outliers segundo esse método? Responda como uma tupla de três elementos (outliers_abaixo, outliers_acima, removeria?) ((int, int, bool))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questoes 6 e 7__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nas questoes  6 e 7 errei a primeira vez de besteira tbm, porque noa contei certa a qtd de ocorrencia e sim alguma outra coisa que ainda nao descobri :|__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Quais são as regiões (variável `Region`) presentes no _data set_? Retorne uma lista com as regiões únicas do _data set_ com os espaços à frente e atrás da string removidos (mas mantenha pontuação: ponto, hífen etc) e ordenadas em ordem alfabética."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    #criando o grupo com as regioes\n",
    "    grupo = aux.groupby(['Region'])\n",
    "    #lista vazia\n",
    "    lista_regioes = []\n",
    "    #pegando tamanho do grupo\n",
    "    y = len(grupo)\n",
    "    # de x ate y == 11\n",
    "    #adiciona na lista os nomes das regioes\n",
    "    for x in range(y):\n",
    "        #print(grupo['Region'].unique()[x][0])\n",
    "        lista_regioes.append(grupo['Region'].unique()[x][0])\n",
    "        \n",
    "    return lista_regioes\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Discretizando a variável `Pop_density` em 10 intervalos com `KBinsDiscretizer`, seguindo o encode `ordinal` e estratégia `quantile`, quantos países se encontram acima do 90º percentil? Responda como um único escalar inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2():\n",
    "    return int(qtd_paises)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "\n",
    "Se codificarmos as variáveis `Region` e `Climate` usando _one-hot encoding_, quantos novos atributos seriam criados? Responda como um único escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3():\n",
    "    return tota_novos_atributos\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n",
    "\n",
    "Aplique o seguinte _pipeline_:\n",
    "\n",
    "1. Preencha as variáveis do tipo `int64` e `float64` com suas respectivas medianas.\n",
    "2. Padronize essas variáveis.\n",
    "\n",
    "Após aplicado o _pipeline_ descrito acima aos dados (somente nas variáveis dos tipos especificados), aplique o mesmo _pipeline_ (ou `ColumnTransformer`) ao dado abaixo. Qual o valor da variável `Arable` após o _pipeline_? Responda como um único float arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_country = [\n",
    "    'Test Country', 'NEAR EAST', -0.19032480757326514,\n",
    "    -0.3232636124824411, -0.04421734470810142, -0.27528113360605316,\n",
    "    0.13255850810281325, -0.8054845935643491, 1.0119784924248225,\n",
    "    0.6189182532646624, 1.0074863283776458, 0.20239896852403538,\n",
    "    -0.043678728558593366, -0.13929748680369286, 1.3163604645710438,\n",
    "    -0.3699637766938669, -0.6149300604558857, -0.854369594993175,\n",
    "    0.263445277972641, 0.5712416961268142\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_colunas = list(aux_pipe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_country = pd.DataFrame(np.array(test_country).reshape(1,20), columns=nome_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_transformation_test_country = aux_pipeline.fit_transform(df_test_country[colunas_int_float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sem sentido total esse negocio de pipeline aki pra isso, pq parece q ja estao padronizados os dados e nem tem valor vazio..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q4():\n",
    "    return round(test_country[11], 3)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 5\n",
    "\n",
    "Descubra o número de _outliers_ da variável `Net_migration` segundo o método do _boxplot_, ou seja, usando a lógica:\n",
    "\n",
    "$$x \\notin [Q1 - 1.5 \\times \\text{IQR}, Q3 + 1.5 \\times \\text{IQR}] \\Rightarrow x \\text{ é outlier}$$\n",
    "\n",
    "que se encontram no grupo inferior e no grupo superior.\n",
    "\n",
    "Você deveria remover da análise as observações consideradas _outliers_ segundo esse método? Responda como uma tupla de três elementos `(outliers_abaixo, outliers_acima, removeria?)` ((int, int, bool))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q5():\n",
    "    # Retorne aqui o resultado da questão 4.\n",
    "    return (int(outliers_abaixo), int(outliers_acima), removeria)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 6\n",
    "Para as questões 6 e 7 utilize a biblioteca `fetch_20newsgroups` de datasets de test do `sklearn`\n",
    "\n",
    "Considere carregar as seguintes categorias e o dataset `newsgroups`:\n",
    "\n",
    "```\n",
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']\n",
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "\n",
    "Aplique `CountVectorizer` ao _data set_ `newsgroups` e descubra o número de vezes que a palavra _phone_ aparece no corpus. Responda como um único escalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sci.electronics', 'comp.graphics', 'rec.motorcycles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsgroup = fetch_20newsgroups(subset=\"train\", categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essse é o tanto de documento..\n",
    "#len(newsgroup.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "##count_vect = CountVectorizer(stop_words= 'english', analyzer='word')\n",
    "count_vect = CountVectorizer()\n",
    "newsgroups_counts = count_vect.fit_transform(newsgroup.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_idx = sorted([count_vect.vocabulary_.get(f'{word.lower()}') for word in [u\"phone\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phone = pd.DataFrame(newsgroups_counts[:, words_idx].toarray(), columns=np.array(count_vect.get_feature_names())[words_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_['phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect.vocabulary_.get('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_ocorrencias = df_phone['phone'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q6():\n",
    "    return int(qtd_ocorrencias)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 7\n",
    "\n",
    "Aplique `TfidfVectorizer` ao _data set_ `newsgroups` e descubra o TF-IDF da palavra _phone_. Responda como um único escalar arredondado para três casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_vectorizer.fit(newsgroup.data)\n",
    "\n",
    "newsgroups_tfidf_vectorized = tfidf_vectorizer.transform(newsgroup.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phone_idf = pd.DataFrame(newsgroups_tfidf_vectorized[:, words_idx].toarray(), columns=np.array(count_vect.get_feature_names())[words_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q7():\n",
    "    return float(round(df_phone_idf.sum(),3))\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
